{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "import cv2\n",
    "import numpy as np\n",
    "# Set logging level for ultralytics\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.CRITICAL)  # Reduce the verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/home/chichi/code/segmentation/models/Pt/yolo11n-seg.pt\")\n",
    "model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_segmentation(input_video_path, output_video_path,model, target_class=\"bottle\"):\n",
    "    # Load the YOLO segmentation model\n",
    "    # model = YOLO(model_name)\n",
    "\n",
    "    # Get the class index for the target class (e.g., \"bottle\")\n",
    "    class_names = model.names\n",
    "    target_class_idx = next((idx for idx, name in class_names.items() if name == target_class), None)\n",
    "    if target_class_idx is None:\n",
    "        print(f\"Class '{target_class}' not found in model classes.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the video capture and writer\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform segmentation on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Copy the original frame to overlay segmentation results\n",
    "        segmented_frame = frame.copy()\n",
    "\n",
    "        for result in results:\n",
    "            if result.masks is not None:\n",
    "                # Only consider masks that match the target class index\n",
    "                masks = result.masks.xyn  # Normalized coordinates for masks\n",
    "                classes = result.boxes.cls  # Class IDs for detected objects\n",
    "\n",
    "                for mask, cls in zip(masks, classes):\n",
    "                    # Check if the detected class is the target class (e.g., \"bottle\")\n",
    "                    if int(cls) == target_class_idx:\n",
    "                        # Convert normalized mask coordinates to absolute frame coordinates\n",
    "                        absolute_mask = (mask * [width, height]).astype(np.int32)\n",
    "\n",
    "                        # Check if mask points are in the right shape (N, 2) before passing to fillPoly\n",
    "                        if absolute_mask.shape[1] == 2 and absolute_mask.ndim == 2:\n",
    "                            # Draw the polygon mask on the frame with a chosen color\n",
    "                            color = (0, 0, 255)  # Red color for bottle segments\n",
    "                            cv2.fillPoly(segmented_frame, [absolute_mask], color=color)\n",
    "\n",
    "        # Display the segmented frame\n",
    "        cv2.imshow(\"Segmented Video\", segmented_frame)\n",
    "\n",
    "        # Write the frame with segmentation overlays\n",
    "        out.write(segmented_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release video capture and writer resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Segmentation video saved successfully for class:\", target_class)\n",
    "\n",
    "# Example usage\n",
    "input_video_path = \"test.mp4\"  # Path to your input video file\n",
    "output_video_path = \"yolov8nengine.mp4\"  # Path to save the output segmented video\n",
    "video_segmentation(input_video_path, output_video_path, model,target_class=\"bottle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(format=\"engine\",half=True,imgsz=640,dynamic=True,batch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Set logging level for ultralytics\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.CRITICAL)  # Reduce verbosity\n",
    "\n",
    "def video_segmentation(input_video_path, output_video_path, model, target_class=\"bottle\", report_path=\"benchmark_report.csv\"):\n",
    "    # Initialize benchmark metrics\n",
    "    class_scores = []\n",
    "    processing_start_time = time.time()  # Start time for processing (excluding video writing)\n",
    "    total_frames = 0\n",
    "\n",
    "    # Get the class index for the target class (e.g., \"bottle\")\n",
    "    class_names = model.names\n",
    "    target_class_idx = next((idx for idx, name in class_names.items() if name == target_class), None)\n",
    "    if target_class_idx is None:\n",
    "        print(f\"Class '{target_class}' not found in model classes.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the video capture and writer\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, video_fps, (width, height))\n",
    "\n",
    "    # Calculate the duration of the video in seconds\n",
    "    total_frames_in_video = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_duration = total_frames_in_video / video_fps if video_fps > 0 else 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Measure start time for the frame processing only\n",
    "        frame_start_time = time.time()\n",
    "\n",
    "        # Perform segmentation on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Copy the original frame to overlay segmentation results\n",
    "        segmented_frame = frame.copy()\n",
    "\n",
    "        frame_scores = []  # Store scores for target class in this frame\n",
    "\n",
    "        for result in results:\n",
    "            if result.masks is not None:\n",
    "                # Only consider masks that match the target class index\n",
    "                masks = result.masks.xyn  # Normalized coordinates for masks\n",
    "                classes = result.boxes.cls  # Class IDs for detected objects\n",
    "                scores = result.boxes.conf  # Confidence scores\n",
    "\n",
    "                for mask, cls, score in zip(masks, classes, scores):\n",
    "                    # Check if the detected class is the target class (e.g., \"bottle\")\n",
    "                    if int(cls) == target_class_idx:\n",
    "                        # Append the score to frame_scores after moving to CPU\n",
    "                        frame_scores.append(score.cpu().numpy())\n",
    "\n",
    "                        # Convert normalized mask coordinates to absolute frame coordinates\n",
    "                        absolute_mask = (mask * [width, height]).astype(np.int32)\n",
    "\n",
    "                        # Check if mask points are in the right shape (N, 2) before passing to fillPoly\n",
    "                        if absolute_mask.shape[1] == 2 and absolute_mask.ndim == 2:\n",
    "                            # Draw the polygon mask on the frame with a chosen color\n",
    "                            color = (0, 0, 255)  # Red color for bottle segments\n",
    "                            cv2.fillPoly(segmented_frame, [absolute_mask], color=color)\n",
    "\n",
    "        # Append the average confidence score of this frame to class_scores (or 0 if no detections)\n",
    "        avg_score = np.mean(frame_scores) if frame_scores else 0\n",
    "        class_scores.append(avg_score)\n",
    "\n",
    "        # Increment frame count\n",
    "        total_frames += 1\n",
    "\n",
    "        # Measure frame processing time without including video writing time\n",
    "        frame_end_time = time.time()\n",
    "        frame_processing_time = frame_end_time - frame_start_time\n",
    "\n",
    "        # Display the segmented frame\n",
    "        cv2.imshow(\"Segmented Video\", segmented_frame)\n",
    "\n",
    "        # Write the frame with segmentation overlays to the output video (excluded from processing time)\n",
    "        out.write(segmented_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release video capture and writer resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Calculate benchmarking metrics\n",
    "    processing_end_time = time.time()\n",
    "    total_processing_time = processing_end_time - processing_start_time  # Only processing time\n",
    "    average_frame_processing_time = total_processing_time / total_frames if total_frames > 0 else 0\n",
    "    average_target_class_score = np.mean(class_scores) * 100  # Convert to percentage\n",
    "    processing_fps = total_frames / total_processing_time if total_processing_time > 0 else 0\n",
    "\n",
    "    # Print benchmarking results\n",
    "    print(f\"Total time: {total_processing_time:.2f} sec\")\n",
    "    print(f\"Video FPS: {video_fps} fps\")\n",
    "    print(f\"Video Duration: {video_duration:.2f} sec\")\n",
    "    print(f\"Average Frame Processing Time: {average_frame_processing_time:.4f} sec\")\n",
    "    print(f\"Target Class Score: {average_target_class_score:.2f}%\")\n",
    "    print(f\"Processing FPS: {processing_fps:.2f} fps\")\n",
    "\n",
    "    # Save benchmark results to a CSV report\n",
    "    report_data = {\n",
    "        \"Metric\": [\n",
    "            \"Total time\", \n",
    "            \"Video FPS\", \n",
    "            \"Video Duration\",\n",
    "            \"Average Frame Processing Time\", \n",
    "            \"Target Class Score\", \n",
    "            \"Processing FPS\"\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            f\"{total_processing_time:.2f} sec\",\n",
    "            f\"{video_fps} fps\",\n",
    "            f\"{video_duration:.2f} sec\",\n",
    "            f\"{average_frame_processing_time:.4f} sec\",\n",
    "            f\"{average_target_class_score:.2f}%\",\n",
    "            f\"{processing_fps:.2f} fps\"\n",
    "        ]\n",
    "    }\n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    report_df.to_csv(report_path, index=False)\n",
    "\n",
    "    print(f\"Benchmark report saved to {report_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_video_path = \"test.mp4\"  # Path to your input video file\n",
    "output_video_path = \"segmented_output_bottle.mp4\"  # Path to save the output segmented video\n",
    "model_path = \"yolov8n-seg.pt\"  # Model path\n",
    "report_path = \"benchmark_report.csv\"  # CSV report file\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Run segmentation and benchmarking\n",
    "video_segmentation(input_video_path, output_video_path, model, target_class=\"bottle\", report_path=report_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Set logging level for ultralytics\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.CRITICAL)  # Reduce verbosity\n",
    "\n",
    "def video_segmentation(input_video_path, output_video_path, model, class_names, target_class=\"bottle\", report_path=\"benchmark_report.csv\"):\n",
    "    # Initialize benchmark metrics\n",
    "    class_scores = []\n",
    "    processing_start_time = time.time()  # Start time for processing (excluding video writing)\n",
    "    total_frames = 0\n",
    "\n",
    "    # Get the class index for the target class (e.g., \"bottle\")\n",
    "    target_class_idx = next((idx for idx, name in class_names.items() if name == target_class), None)\n",
    "    if target_class_idx is None:\n",
    "        print(f\"Class '{target_class}' not found in model classes.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the video capture and writer\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, video_fps, (width, height))\n",
    "\n",
    "    # Calculate the duration of the video in seconds\n",
    "    total_frames_in_video = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_duration = total_frames_in_video / video_fps if video_fps > 0 else 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Measure start time for the frame processing only\n",
    "        frame_start_time = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Perform segmentation on the frame\n",
    "            results = model(frame)\n",
    "\n",
    "            # Copy the original frame to overlay segmentation results\n",
    "            segmented_frame = frame.copy()\n",
    "\n",
    "            frame_scores = []  # Store scores for target class in this frame\n",
    "\n",
    "            for result in results:\n",
    "                if result.masks is not None:\n",
    "                    # Only consider masks that match the target class index\n",
    "                    masks = result.masks.xyn  # Normalized coordinates for masks\n",
    "                    classes = result.boxes.cls  # Class IDs for detected objects\n",
    "                    scores = result.boxes.conf  # Confidence scores\n",
    "\n",
    "                    for mask, cls, score in zip(masks, classes, scores):\n",
    "                        # Check if the detected class is the target class (e.g., \"bottle\")\n",
    "                        if int(cls) == target_class_idx:\n",
    "                            # Append the score to frame_scores after moving to CPU\n",
    "                            frame_scores.append(score.cpu().numpy())\n",
    "\n",
    "                            # Convert normalized mask coordinates to absolute frame coordinates\n",
    "                            absolute_mask = (mask * [width, height]).astype(np.int32)\n",
    "\n",
    "                            # Check if mask points are in the right shape (N, 2) before passing to fillPoly\n",
    "                            if absolute_mask.shape[1] == 2 and absolute_mask.ndim == 2:\n",
    "                                # Draw the polygon mask on the frame with a chosen color\n",
    "                                color = (0, 0, 255)  # Red color for bottle segments\n",
    "                                cv2.fillPoly(segmented_frame, [absolute_mask], color=color)\n",
    "\n",
    "        # Append the average confidence score of this frame to class_scores (or 0 if no detections)\n",
    "        avg_score = np.mean(frame_scores) if frame_scores else 0\n",
    "        class_scores.append(avg_score)\n",
    "\n",
    "        # Increment frame count\n",
    "        total_frames += 1\n",
    "\n",
    "        # Measure frame processing time without including video writing time\n",
    "        frame_end_time = time.time()\n",
    "        frame_processing_time = frame_end_time - frame_start_time\n",
    "\n",
    "        # Display the segmented frame\n",
    "        # cv2.imshow(\"Segmented Video\", segmented_frame)\n",
    "\n",
    "        # Write the frame with segmentation overlays to the output video (excluded from processing time)\n",
    "        out.write(segmented_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Clean up variables\n",
    "        del results\n",
    "        del segmented_frame\n",
    "        del frame_scores\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Release video capture and writer resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Calculate benchmarking metrics\n",
    "    processing_end_time = time.time()\n",
    "    total_processing_time = processing_end_time - processing_start_time  # Only processing time\n",
    "    average_frame_processing_time = total_processing_time / total_frames if total_frames > 0 else 0\n",
    "    average_target_class_score = np.mean(class_scores) * 100  # Convert to percentage\n",
    "    processing_fps = total_frames / total_processing_time if total_processing_time > 0 else 0\n",
    "\n",
    "    # Print benchmarking results\n",
    "    print(f\"Total time: {total_processing_time:.2f} sec\")\n",
    "    print(f\"Video FPS: {video_fps} fps\")\n",
    "    print(f\"Video Duration: {video_duration:.2f} sec\")\n",
    "    print(f\"Average Frame Processing Time: {average_frame_processing_time:.4f} sec\")\n",
    "    print(f\"Target Class Score: {average_target_class_score:.2f}%\")\n",
    "    print(f\"Processing FPS: {processing_fps:.2f} fps\")\n",
    "\n",
    "    # Save benchmark results to a CSV report\n",
    "    report_data = {\n",
    "        \"Metric\": [\n",
    "            \"Total time\", \n",
    "            \"Video FPS\", \n",
    "            \"Video Duration\",\n",
    "            \"Average Frame Processing Time\", \n",
    "            \"Target Class Score\", \n",
    "            \"Processing FPS\"\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            f\"{total_processing_time:.2f} sec\",\n",
    "            f\"{video_fps} fps\",\n",
    "            f\"{video_duration:.2f} sec\",\n",
    "            f\"{average_frame_processing_time:.4f} sec\",\n",
    "            f\"{average_target_class_score:.2f}%\",\n",
    "            f\"{processing_fps:.2f} fps\"\n",
    "        ]\n",
    "    }\n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    report_df.to_csv(report_path, index=False)\n",
    "\n",
    "    print(f\"Benchmark report saved to {report_path}\")\n",
    "\n",
    "def clear_cuda_cache():\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.cuda.device(0):\n",
    "        torch.cuda.ipc_collect()\n",
    "    gc.collect()\n",
    "\n",
    "def benchmark_all_models(models_dir, input_video_path, report_base_dir, output_video_base_dir):\n",
    "    # Create base directories for reports and videos\n",
    "    os.makedirs(report_base_dir, exist_ok=True)\n",
    "    os.makedirs(output_video_base_dir, exist_ok=True)\n",
    "    \n",
    "    # Get video duration, fps, and name\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames_in_video = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_duration = total_frames_in_video / video_fps if video_fps > 0 else 0\n",
    "    cap.release()\n",
    "    video_name = os.path.splitext(os.path.basename(input_video_path))[0]\n",
    "\n",
    "    # Include video name, duration, and FPS in the directory name\n",
    "    video_info_dir = f\"{video_name}_{int(video_duration)} seconds_{video_fps}fps\"\n",
    "    \n",
    "    for model_type in [\"onnx\", \"TensorRT\", \"Pt\"]:\n",
    "        model_type_dir = os.path.join(models_dir, model_type)\n",
    "        if not os.path.isdir(model_type_dir):\n",
    "            continue  # Skip if model type directory does not exist\n",
    "\n",
    "        for model_file in os.listdir(model_type_dir):\n",
    "            model_path = os.path.join(model_type_dir, model_file)\n",
    "            if not os.path.isfile(model_path):\n",
    "                continue  # Skip if it's not a file\n",
    "\n",
    "            # Set paths for saving output video and report\n",
    "            model_name, _ = os.path.splitext(model_file)\n",
    "            output_video_dir = os.path.join(output_video_base_dir, video_info_dir, model_type)\n",
    "            os.makedirs(output_video_dir, exist_ok=True)\n",
    "            output_video_path = os.path.join(output_video_dir, f\"{model_name}.mp4\")\n",
    "\n",
    "            report_dir = os.path.join(report_base_dir, video_info_dir, model_type)\n",
    "            os.makedirs(report_dir, exist_ok=True)\n",
    "            report_path = os.path.join(report_dir, f\"{model_name}.csv\")\n",
    "\n",
    "            try:\n",
    "                # Load model based on file type\n",
    "                print(f\"Benchmarking model: {model_name}\")\n",
    "\n",
    "                # Clear cache before loading model\n",
    "                clear_cuda_cache()\n",
    "\n",
    "                if model_type == \"Pt\":\n",
    "                    # Load .pt model with CUDA if available\n",
    "                    model = YOLO(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                else:\n",
    "                    # Load .onnx or .engine model without device setting\n",
    "                    model = YOLO(model_path)\n",
    "\n",
    "                # Define default class names if not available\n",
    "                class_names = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
    "\n",
    "                # Run video segmentation and benchmarking\n",
    "                video_segmentation(input_video_path, output_video_path, model, class_names, report_path=report_path)\n",
    "\n",
    "                # Clear GPU memory after processing each model\n",
    "                del model\n",
    "                clear_cuda_cache()\n",
    "                gc.collect()\n",
    "                print(f\"Cleared GPU memory after benchmarking model: {model_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing model {model_name}: {e}\")\n",
    "                del model\n",
    "                clear_cuda_cache()\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "# Example usage\n",
    "models_dir = \"./models\"\n",
    "input_video_path = \"test_5.mp4\"\n",
    "report_base_dir = \"./report\"\n",
    "output_video_base_dir = \"./segmented_videos\"\n",
    "\n",
    "benchmark_all_models(models_dir, input_video_path, report_base_dir, output_video_base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def reduce_fps(input_file, output_file):\n",
    "    # Load the video\n",
    "    clip = VideoFileClip(input_file)\n",
    "\n",
    "    # Set the new frame rate to 15 fps\n",
    "    clip = clip.set_fps(15)\n",
    "\n",
    "    # Write the result to the output file\n",
    "    clip.write_videofile(output_file, fps=15)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the paths to your input and output videos here\n",
    "    input_file = \"/home/chichi/code/segmentation/test_1.mp4\"   # Replace with your input video path\n",
    "    output_file = \"/home/chichi/code/segmentation/test_4.mp4\" # Replace with your output video path\n",
    "\n",
    "    reduce_fps(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restructured combined report saved to restructured_combined_report.csv\n",
      "              Test_Folder Model_Format   Model_Name  \\\n",
      "0  test_0_1 seconds_30fps           Pt  yolo11m-seg   \n",
      "1  test_0_1 seconds_30fps           Pt  yolo11n-seg   \n",
      "2  test_0_1 seconds_30fps           Pt  yolo11s-seg   \n",
      "3  test_0_1 seconds_30fps           Pt  yolov8m-seg   \n",
      "4  test_0_1 seconds_30fps           Pt  yolov8n-seg   \n",
      "\n",
      "  Average Frame Processing Time Processing FPS Target Class Score Total time  \\\n",
      "0                    0.0591 sec      16.91 fps             51.16%   1.77 sec   \n",
      "1                    0.0329 sec      30.38 fps             37.44%   0.99 sec   \n",
      "2                    0.0397 sec      25.21 fps             47.02%   1.19 sec   \n",
      "3                    0.0579 sec      17.26 fps             50.18%   1.74 sec   \n",
      "4                    0.0298 sec      33.51 fps             36.07%   0.90 sec   \n",
      "\n",
      "  Video Duration Video FPS  \n",
      "0       1.00 sec    30 fps  \n",
      "1       1.00 sec    30 fps  \n",
      "2       1.00 sec    30 fps  \n",
      "3       1.00 sec    30 fps  \n",
      "4       1.00 sec    30 fps  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing the model reports\n",
    "root_dir = './report/'  # Adjust this path if necessary\n",
    "output_file = 'combined_report.csv'\n",
    "\n",
    "# Initialize an empty DataFrame to hold all data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Walk through each test folder in the directory\n",
    "for test_folder in os.listdir(root_dir):\n",
    "    test_folder_path = os.path.join(root_dir, test_folder)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(test_folder_path):\n",
    "        # Now look inside each model format folder (onnx, TensorRT, Pt)\n",
    "        for model_format in os.listdir(test_folder_path):\n",
    "            model_format_path = os.path.join(test_folder_path, model_format)\n",
    "            \n",
    "            # Check if it's a directory\n",
    "            if os.path.isdir(model_format_path):\n",
    "                \n",
    "                # Iterate over each CSV file within the model format folder\n",
    "                for csv_file in os.listdir(model_format_path):\n",
    "                    if csv_file.endswith('.csv'):\n",
    "                        \n",
    "                        # Extract model name from the file name (without extension)\n",
    "                        model_name = os.path.splitext(csv_file)[0]\n",
    "                        \n",
    "                        # Load the CSV data\n",
    "                        csv_path = os.path.join(model_format_path, csv_file)\n",
    "                        \n",
    "                        try:\n",
    "                            data = pd.read_csv(csv_path)\n",
    "                            \n",
    "                            # Add columns for test folder, model format, and model name\n",
    "                            data['Test_Folder'] = test_folder\n",
    "                            data['Model_Format'] = model_format\n",
    "                            data['Model_Name'] = model_name\n",
    "                            \n",
    "                            # Append the data to the all_data DataFrame\n",
    "                            all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error reading {csv_file}: {e}\")\n",
    "\n",
    "# Restructure the data into a table format\n",
    "restructured_report = all_data.pivot_table(\n",
    "    index=['Test_Folder', 'Model_Format', 'Model_Name'],\n",
    "    columns='Metric',\n",
    "    values='Value',\n",
    "    aggfunc='first'  # Use first as there's only one value per metric in each file\n",
    ").reset_index()\n",
    "\n",
    "# Flatten the columns\n",
    "restructured_report.columns.name = None  # Remove the name of the column index\n",
    "restructured_report.columns = [str(col) for col in restructured_report.columns]  # Flatten\n",
    "\n",
    "# Save the restructured data to a CSV file\n",
    "restructured_output_file = 'report.csv'\n",
    "restructured_report.to_csv(restructured_output_file, index=False)\n",
    "print(f\"Restructured combined report saved to {restructured_output_file}\")\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(restructured_report.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
